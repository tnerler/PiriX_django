# retrieve_and_generate.py
from typing_extensions import List, TypedDict
from langchain.schema import Document
from utils._faiss import build_store
from utils.load_docs import load_docs
from utils.openai_clients import get_llm
from operator import itemgetter
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate
from sentence_transformers import CrossEncoder

cross_encoder = CrossEncoder("cross-encoder/ms-marco-TinyBERT-L-6")

class State(TypedDict):
    question: str
    context: str
    answer: str

def build_chatbot():  
    docs = load_docs()
    vector_store = build_store(docs)

    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        input_key='question',
        output_key="answer"
    )

    template = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(
        """
        Sen PiriX'sin, Piri Reis Ãœniversitesi'nin bilgi asistanÄ±sÄ±n. Temel gÃ¶revin: Okul hakkÄ±nda kÄ±sa, doÄŸru ve anlaÅŸÄ±lÄ±r bilgiler vermek.

        Ã–NEMLÄ° KURALLAR:
        1. SADECE Piri Reis Ãœniversitesi konularÄ±na yanÄ±t ver. DiÄŸer konularda: "Ben sadece Piri Reis Ãœniversitesi hakkÄ±nda bilgi verebilirim ğŸ’™ DiÄŸer konular iÃ§in baÅŸka bir asistana sormanÄ± Ã¶neririm!"

        2. BilmediÄŸin konularda: "Bu konuda ÅŸu anda elimde bilgi yok. DetaylÄ± bilgi iÃ§in Ã§aÄŸrÄ± merkezimizi arayabilirsiniz: +90 216 581 00 50"

        3. Samimi ve arkadaÅŸÃ§a konuÅŸ, robot gibi yanÄ±tlardan kaÃ§Ä±n. Emoji kullanabilirsin ğŸ˜Š

        4. Fiyat bilgilerinde her zaman "2025-2026 yÄ±lÄ± Ã¼cretleri" olduÄŸunu belirt ve ÅŸunu ekle: "Daha fazla detay iÃ§in: https://aday.pirireis.edu.tr/ucretler/"

        5. BÃ¶lÃ¼m/kulÃ¼p listeleri sorulursa, verilen bilgilere sadÄ±k kalarak numaralÄ± liste kullan. Uydurma.

        6. Okul tanÄ±tÄ±mÄ± sorularÄ±nda gÃ¼Ã§lÃ¼ yÃ¶nleri vurgula ama abartma.

        7. YanÄ±tlar her zaman doÄŸru, kÄ±sa ve net olmalÄ±.
        """
    ),
    MessagesPlaceholder(variable_name="chat_history"),
    HumanMessagePromptTemplate.from_template(
        "BaÄŸlam: {context}\nSoru: {question}\nCevap:"
    ),
])

    chain = template | get_llm()

    def retrieve(state: State):
        query = state["question"]
        
        # Ä°lk aÅŸama: VektÃ¶r veritabanÄ±ndan benzer dokÃ¼manlarÄ± getir
        results = vector_store.similarity_search_with_score(query, k=10)
        top_docs = [doc for doc, _ in results]
        
        # Ä°kinci aÅŸama: Cross-encoder ile dokÃ¼manlarÄ± yeniden sÄ±rala
        cross_encoder_inputs = [(query, doc.page_content) for doc in top_docs]
        scores = cross_encoder.predict(cross_encoder_inputs)
        
        # SonuÃ§larÄ± skorlarÄ±na gÃ¶re sÄ±rala ve en iyi 5'ini al
        reranked_docs = [
            doc for _, doc in sorted(zip(scores, top_docs), key=itemgetter(0), reverse=True)
        ][:5]

        return {
            "context": reranked_docs,
            "question": query
        }

    def generate(state: State):
        if not state["context"]:
            return {"answer": "Bu konuda ÅŸu anda elimde bilgi yok. DetaylÄ± bilgi iÃ§in Ã§aÄŸrÄ± merkezimizi arayabilirsiniz: +90 216 581 00 50"}

        docs_content = "\n\n".join(doc.page_content for doc in state['context'])
        chat_history = memory.load_memory_variables({}).get("chat_history", [])

        input_data = {
            "context": docs_content,
            "question": state["question"],
            "chat_history": chat_history
        }

        answer = chain.invoke(input_data)
        memory.save_context({"question": state["question"]}, {"answer": answer.content})

        return {"answer": answer.content}

    return retrieve, generate